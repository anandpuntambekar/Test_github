{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1fvn8oFZ-yPVfitvkVgSlKkUnyN49y4Dk",
      "authorship_tag": "ABX9TyPp1+hIOLFub5YSzjPnXLsH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandpuntambekar/Test_github/blob/master/Hangman_attempt_5_recap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "import collections\n",
        "#torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "iTItmV9TaApK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj6jE2WkWMe8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "import collections\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(QNetwork, self).__init__()\n",
        "\n",
        "        # First hidden layer\n",
        "        self.fc1 = nn.Linear(input_dim, 64)  # Increased neurons to 64\n",
        "        # Second hidden layer\n",
        "        self.fc2 = nn.Linear(64, 64)  # Introduced an additional layer with 64 neurons\n",
        "        # Third hidden layer\n",
        "        self.fc3 = nn.Linear(64, 48)  # Introduced another layer with 48 neurons\n",
        "        # Output layer\n",
        "        self.fc4 = nn.Linear(48, output_dim)\n",
        "\n",
        "        # Initialize weights with Kaiming Initialization for LeakyReLU\n",
        "        '''\n",
        "        init.kaiming_normal_(self.fc1.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc2.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc3.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc4.weight, nonlinearity='leaky_relu')\n",
        "        '''\n",
        "        # Define LeakyReLU activation function\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        return self.fc4(x)\n",
        "\n",
        "\n",
        "class HangmanDQL:\n",
        "    def __init__(self, word_list):\n",
        "        self.word_list = word_list\n",
        "        self.epsilon = 0.2\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.95\n",
        "        self.learning_rate = 3*0.0001 #0.00055 #0.001\n",
        "        self.model = QNetwork(26 + 29+5, 26).to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.MAX_CHANCES = 10\n",
        "\n",
        "    def get_state(self, word, used_letters,incorrect_guesses):\n",
        "        state = [1 if char in used_letters else 0 for char in 'abcdefghijklmnopqrstuvwxyz']\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word]\n",
        "\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word] + [0] * (29 - len(word))\n",
        "\n",
        "        # Change word encoding to put -1 if the word is not required or out of scope\n",
        "        word_encoding = [1 if char == \"_\" else 0 for char in word] + [-1] * (29 - len(word))\n",
        "\n",
        "        # a. Length of the word being guessed\n",
        "        word_length = len(word)\n",
        "\n",
        "        # b. Count of correct letters guessed in the current word state\n",
        "        correct_letter_count = sum(word.count(letter) for letter in set(word) if letter != '_')\n",
        "\n",
        "        # c. Total positions correctly guessed\n",
        "        correct_positions = len(word) - word_encoding.count(1)\n",
        "\n",
        "        # d. Total guesses pending\n",
        "        guesses_pending = len(word) - correct_positions\n",
        "\n",
        "        # e. Total chances pending\n",
        "        chances_pending = self.MAX_CHANCES - incorrect_guesses\n",
        "\n",
        "        state_representation = state + word_encoding\n",
        "        #print(\"State representation length:\", len(state_representation))\n",
        "\n",
        "        # sugession\n",
        "        # If you have gussed first word correctly - add a single state to represent what was the first word\n",
        "        # If you have gussed last word correctly - add a single state to represent what was the last word\n",
        "        state_representation = state + word_encoding + [word_length, correct_letter_count, correct_positions, guesses_pending, chances_pending]\n",
        "\n",
        "        return torch.tensor(state_representation, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "          target = reward\n",
        "          if not done:\n",
        "              target = reward + self.gamma * torch.argmax(self.model(next_state)).item()\n",
        "          '''\n",
        "          target_q_values = self.model(state)\n",
        "\n",
        "          # Prepare data for CrossEntropy loss\n",
        "          action_idx = ord(action) - 97\n",
        "          loss = self.criterion(target_q_values, torch.tensor([action_idx]).to(device))\n",
        "          '''\n",
        "          predicted_q_values = self.model(state)\n",
        "          target_q_values = predicted_q_values.clone().detach()\n",
        "          action_idx = ord(action) - 97\n",
        "          target_q_values[0][action_idx] = target\n",
        "          loss = nn.MSELoss()(predicted_q_values, target_q_values)\n",
        "\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def guess(self, word): # word input example: \"_ p p _ e \"\n",
        "        ###############################################\n",
        "        # Replace with your own \"guess\" function here #\n",
        "        ###############################################\n",
        "\n",
        "        # clean the word so that we strip away the space characters\n",
        "        # replace \"_\" with \".\" as \".\" indicates any character in regular expressions\n",
        "        clean_word = word[::2].replace(\"_\",\".\")\n",
        "\n",
        "        # find length of passed word\n",
        "        len_word = len(clean_word)\n",
        "\n",
        "        # grab current dictionary of possible words from self object, initialize new possible words dictionary to empty\n",
        "        current_dictionary = self.word_list\n",
        "        new_dictionary = []\n",
        "\n",
        "        # iterate through all of the words in the old plausible dictionary\n",
        "        for dict_word in current_dictionary:\n",
        "            # continue if the word is not of the appropriate length\n",
        "            if len(dict_word) != len_word:\n",
        "                continue\n",
        "\n",
        "            # if dictionary word is a possible match then add it to the current dictionary\n",
        "            if re.match(clean_word,dict_word):\n",
        "                new_dictionary.append(dict_word)\n",
        "\n",
        "        # overwrite old possible words dictionary with updated version\n",
        "        self.current_dictionary = new_dictionary\n",
        "\n",
        "\n",
        "        # count occurrence of all characters in possible word matches\n",
        "        full_dict_string = \"\".join(new_dictionary)\n",
        "\n",
        "        c = collections.Counter(full_dict_string)\n",
        "        sorted_letter_count = c.most_common()\n",
        "\n",
        "        guess_letter = '!'\n",
        "\n",
        "        # return most frequently occurring letter in all possible words that hasn't been guessed yet\n",
        "        for letter,instance_count in sorted_letter_count:\n",
        "            if letter not in self.guessed_letters:\n",
        "                guess_letter = letter\n",
        "                break\n",
        "\n",
        "        # if no word matches in training dictionary, default back to ordering of full dictionary\n",
        "        if guess_letter == '!':\n",
        "            sorted_letter_count = self.full_dictionary_common_letter_sorted\n",
        "            for letter,instance_count in sorted_letter_count:\n",
        "                if letter not in self.guessed_letters:\n",
        "                    guess_letter = letter\n",
        "                    break\n",
        "\n",
        "        return guess_letter\n",
        "\n",
        "    def choose_action(self, state, use_guess_function=False):\n",
        "        if use_guess_function:\n",
        "            # Transform state back to the word representation\n",
        "            word = ''.join(['_' if char == 1 else char for char in state[0][-34:-5].tolist()])  # adjusted indices based on your state representation\n",
        "            return self.guess(word)\n",
        "        else:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "              return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = nn.functional.softmax(self.model(state), dim=-1)  # Apply softmax here\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def train(self, epochs=1000, batch_size=32, guess_epochs=2000):\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            use_guess_function = _ < guess_epochs\n",
        "            use_guess_function=False\n",
        "            print(f'Training Epoch: {_ + 1}/{epochs}')\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses=0\n",
        "            done = False\n",
        "            ## If you have gussed the complete word get a + 10 reward\n",
        "            ## if you have reached the limit of incorrect gusses you get a -10\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #action = self.choose_action(state)\n",
        "                action = self.choose_action(state, use_guess_function)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "                    incorrect_guesses += 1\n",
        "                # Check if the entire word has been guessed\n",
        "                if \"_\" not in guessed_word:\n",
        "                    reward = 10\n",
        "                    done = True\n",
        "\n",
        "                # Check if the limit of incorrect guesses has been reached\n",
        "                if incorrect_guesses >= self.MAX_CHANCES:\n",
        "                    reward = -10\n",
        "                    done = True\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "\n",
        "                if len(self.memory) > batch_size:\n",
        "                    self.replay(batch_size)\n",
        "            success_rate = self.test(games=500)\n",
        "            #print(f\"Success Rate after Epoch {_ + 1}: {success_rate:.2%}\")\n",
        "\n",
        "    def find_learning_rate(self, init_value=1e-8, final_value=10., beta=0.98):\n",
        "        num = len(self.memory) - 1\n",
        "        mult = (final_value / init_value) ** (1/num)\n",
        "        lr = init_value\n",
        "        self.optimizer.param_groups[0]['lr'] = lr\n",
        "        avg_loss = 0.\n",
        "        best_loss = 0.\n",
        "        batch_num = 0\n",
        "        losses = []\n",
        "        log_lrs = []\n",
        "        for data in self.memory:\n",
        "            batch_num += 1\n",
        "            # Get a mini-batch of training data\n",
        "            state, action, reward, next_state, done = data\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            # Smooth the average and compute the smoothed loss\n",
        "            avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
        "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "\n",
        "            # Stop if the loss is exploding\n",
        "            if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "                return log_lrs, losses\n",
        "            # Record the best loss\n",
        "            if smoothed_loss < best_loss or batch_num==1:\n",
        "                best_loss = smoothed_loss\n",
        "\n",
        "            # Store the values\n",
        "            losses.append(smoothed_loss)\n",
        "            log_lrs.append(np.log10(lr))\n",
        "\n",
        "            # Update the learning rate\n",
        "            lr *= mult\n",
        "            self.optimizer.param_groups[0]['lr'] = lr\n",
        "\n",
        "            # Perform the optimization step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return log_lrs, losses\n",
        "\n",
        "    def plot_lr_finder(self, log_lrs, losses):\n",
        "        plt.plot(log_lrs, losses)\n",
        "        plt.xlabel(\"Log10 Learning Rate\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Learning Rate Finder\")\n",
        "        plt.show()\n",
        "\n",
        "    def populate_memory(self, games=500):\n",
        "        for _ in range(games):\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses = 0  # Initialize it here\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #print(\"State shape:\", state.shape)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                #print(state.shape)\n",
        "                #print(26 + len(max(self.word_list, key=len)))\n",
        "\n",
        "    def test(self, games=100):\n",
        "      total_success = 0\n",
        "\n",
        "      for _ in range(games):\n",
        "          word = np.random.choice(self.word_list)\n",
        "          guessed_word = [\"_\"] * len(word)\n",
        "          used_letters = []\n",
        "          incorrect_guesses = 0\n",
        "          game_over = False\n",
        "\n",
        "          while not game_over:\n",
        "              state = self.get_state(\"\".join(guessed_word), used_letters, incorrect_guesses)\n",
        "              #q_values = self.model(state).detach().cpu().numpy()  # Get Q-values for actions\n",
        "              q_values = nn.functional.softmax(self.model(state), dim=-1).detach().cpu().numpy()\n",
        "              # Exclude already used letters\n",
        "              for used_letter in used_letters:\n",
        "                  q_values[0][ord(used_letter) - 97] = -np.inf\n",
        "\n",
        "              action = chr(np.argmax(q_values) + 97)\n",
        "              used_letters.append(action)\n",
        "\n",
        "              if action in word:\n",
        "                  for i, letter in enumerate(word):\n",
        "                      if letter == action:\n",
        "                          guessed_word[i] = action\n",
        "              else:\n",
        "                incorrect_guesses += 1  # Increment the counter if the guess was incorrect\n",
        "\n",
        "\n",
        "              game_over = \"_\" not in guessed_word or len(used_letters) > 10\n",
        "\n",
        "          # Check if the game was a success\n",
        "          if \"_\" not in guessed_word:\n",
        "              total_success += 1\n",
        "\n",
        "      print(f\"Success rate: {total_success/games:.2%}\")\n",
        "      return total_success"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HangmanDQL:\n",
        "    def __init__(self, word_list):\n",
        "        self.word_list = word_list\n",
        "        self.epsilon = 0.2\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.95\n",
        "        self.learning_rate = 3*0.0001 #0.00055 #0.001\n",
        "        self.model = QNetwork(26 + 29+5, 26).to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.MAX_CHANCES = 10\n",
        "\n",
        "    def get_state(self, word, used_letters,incorrect_guesses):\n",
        "        state = [1 if char in used_letters else 0 for char in 'abcdefghijklmnopqrstuvwxyz']\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word]\n",
        "\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word] + [0] * (29 - len(word))\n",
        "\n",
        "        # Change word encoding to put -1 if the word is not required or out of scope\n",
        "        word_encoding = [1 if char == \"_\" else 0 for char in word] + [-1] * (29 - len(word))\n",
        "\n",
        "        # a. Length of the word being guessed\n",
        "        word_length = len(word)\n",
        "\n",
        "        # b. Count of correct letters guessed in the current word state\n",
        "        correct_letter_count = sum(word.count(letter) for letter in set(word) if letter != '_')\n",
        "\n",
        "        # c. Total positions correctly guessed\n",
        "        correct_positions = len(word) - word_encoding.count(1)\n",
        "\n",
        "        # d. Total guesses pending\n",
        "        guesses_pending = len(word) - correct_positions\n",
        "\n",
        "        # e. Total chances pending\n",
        "        chances_pending = self.MAX_CHANCES - incorrect_guesses\n",
        "\n",
        "        state_representation = state + word_encoding\n",
        "        #print(\"State representation length:\", len(state_representation))\n",
        "\n",
        "        # sugession\n",
        "        # If you have gussed first word correctly - add a single state to represent what was the first word\n",
        "        # If you have gussed last word correctly - add a single state to represent what was the last word\n",
        "        state_representation = state + word_encoding + [word_length, correct_letter_count, correct_positions, guesses_pending, chances_pending]\n",
        "\n",
        "        return torch.tensor(state_representation, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "          target = reward\n",
        "          if not done:\n",
        "              target = reward + self.gamma * torch.argmax(self.model(next_state)).item()\n",
        "          '''\n",
        "          target_q_values = self.model(state)\n",
        "\n",
        "          # Prepare data for CrossEntropy loss\n",
        "          action_idx = ord(action) - 97\n",
        "          loss = self.criterion(target_q_values, torch.tensor([action_idx]).to(device))\n",
        "          '''\n",
        "          predicted_q_values = self.model(state)\n",
        "          target_q_values = predicted_q_values.clone().detach()\n",
        "          action_idx = ord(action) - 97\n",
        "          target_q_values[0][action_idx] = target\n",
        "          loss = nn.MSELoss()(predicted_q_values, target_q_values)\n",
        "\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def guess(self, word): # word input example: \"_ p p _ e \"\n",
        "        ###############################################\n",
        "        # Replace with your own \"guess\" function here #\n",
        "        ###############################################\n",
        "\n",
        "        # clean the word so that we strip away the space characters\n",
        "        # replace \"_\" with \".\" as \".\" indicates any character in regular expressions\n",
        "        clean_word = word[::2].replace(\"_\",\".\")\n",
        "\n",
        "        # find length of passed word\n",
        "        len_word = len(clean_word)\n",
        "\n",
        "        # grab current dictionary of possible words from self object, initialize new possible words dictionary to empty\n",
        "        current_dictionary = self.word_list\n",
        "        new_dictionary = []\n",
        "\n",
        "        # iterate through all of the words in the old plausible dictionary\n",
        "        for dict_word in current_dictionary:\n",
        "            # continue if the word is not of the appropriate length\n",
        "            if len(dict_word) != len_word:\n",
        "                continue\n",
        "\n",
        "            # if dictionary word is a possible match then add it to the current dictionary\n",
        "            if re.match(clean_word,dict_word):\n",
        "                new_dictionary.append(dict_word)\n",
        "\n",
        "        # overwrite old possible words dictionary with updated version\n",
        "        self.current_dictionary = new_dictionary\n",
        "\n",
        "\n",
        "        # count occurrence of all characters in possible word matches\n",
        "        full_dict_string = \"\".join(new_dictionary)\n",
        "\n",
        "        c = collections.Counter(full_dict_string)\n",
        "        sorted_letter_count = c.most_common()\n",
        "\n",
        "        guess_letter = '!'\n",
        "\n",
        "        # return most frequently occurring letter in all possible words that hasn't been guessed yet\n",
        "        for letter,instance_count in sorted_letter_count:\n",
        "            if letter not in self.guessed_letters:\n",
        "                guess_letter = letter\n",
        "                break\n",
        "\n",
        "        # if no word matches in training dictionary, default back to ordering of full dictionary\n",
        "        if guess_letter == '!':\n",
        "            sorted_letter_count = self.full_dictionary_common_letter_sorted\n",
        "            for letter,instance_count in sorted_letter_count:\n",
        "                if letter not in self.guessed_letters:\n",
        "                    guess_letter = letter\n",
        "                    break\n",
        "\n",
        "        return guess_letter\n",
        "\n",
        "    def choose_action(self, state, use_guess_function=False):\n",
        "        if use_guess_function:\n",
        "            # Transform state back to the word representation\n",
        "            word = ''.join(['_' if char == 1 else char for char in state[0][-34:-5].tolist()])  # adjusted indices based on your state representation\n",
        "            return self.guess(word)\n",
        "        else:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "              return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = nn.functional.softmax(self.model(state), dim=-1)  # Apply softmax here\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def train(self, epochs=1000, batch_size=32, guess_epochs=2000):\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            use_guess_function = _ < guess_epochs\n",
        "            use_guess_function=False\n",
        "            print(f'Training Epoch: {_ + 1}/{epochs}')\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses=0\n",
        "            done = False\n",
        "            ## If you have gussed the complete word get a + 10 reward\n",
        "            ## if you have reached the limit of incorrect gusses you get a -10\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #action = self.choose_action(state)\n",
        "                action = self.choose_action(state, use_guess_function)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "                    incorrect_guesses += 1\n",
        "                # Check if the entire word has been guessed\n",
        "                if \"_\" not in guessed_word:\n",
        "                    reward = 10\n",
        "                    done = True\n",
        "\n",
        "                # Check if the limit of incorrect guesses has been reached\n",
        "                if incorrect_guesses >= self.MAX_CHANCES:\n",
        "                    reward = -10\n",
        "                    done = True\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "\n",
        "                if len(self.memory) > batch_size:\n",
        "                    self.replay(batch_size)\n",
        "            success_rate = self.test(games=500)\n",
        "            #print(f\"Success Rate after Epoch {_ + 1}: {success_rate:.2%}\")\n",
        "\n",
        "    def find_learning_rate(self, init_value=1e-8, final_value=10., beta=0.98):\n",
        "        num = len(self.memory) - 1\n",
        "        mult = (final_value / init_value) ** (1/num)\n",
        "        lr = init_value\n",
        "        self.optimizer.param_groups[0]['lr'] = lr\n",
        "        avg_loss = 0.\n",
        "        best_loss = 0.\n",
        "        batch_num = 0\n",
        "        losses = []\n",
        "        log_lrs = []\n",
        "        for data in self.memory:\n",
        "            batch_num += 1\n",
        "            # Get a mini-batch of training data\n",
        "            state, action, reward, next_state, done = data\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            # Smooth the average and compute the smoothed loss\n",
        "            avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
        "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "\n",
        "            # Stop if the loss is exploding\n",
        "            if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "                return log_lrs, losses\n",
        "            # Record the best loss\n",
        "            if smoothed_loss < best_loss or batch_num==1:\n",
        "                best_loss = smoothed_loss\n",
        "\n",
        "            # Store the values\n",
        "            losses.append(smoothed_loss)\n",
        "            log_lrs.append(np.log10(lr))\n",
        "\n",
        "            # Update the learning rate\n",
        "            lr *= mult\n",
        "            self.optimizer.param_groups[0]['lr'] = lr\n",
        "\n",
        "            # Perform the optimization step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return log_lrs, losses\n",
        "\n",
        "    def plot_lr_finder(self, log_lrs, losses):\n",
        "        plt.plot(log_lrs, losses)\n",
        "        plt.xlabel(\"Log10 Learning Rate\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Learning Rate Finder\")\n",
        "        plt.show()\n",
        "\n",
        "    def populate_memory(self, games=500):\n",
        "        for _ in range(games):\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses = 0  # Initialize it here\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #print(\"State shape:\", state.shape)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                #print(state.shape)\n",
        "                #print(26 + len(max(self.word_list, key=len)))\n",
        "\n",
        "    def test(self, games=100):\n",
        "      total_success = 0\n",
        "\n",
        "      for _ in range(games):\n",
        "          word = np.random.choice(self.word_list)\n",
        "          guessed_word = [\"_\"] * len(word)\n",
        "          used_letters = []\n",
        "          incorrect_guesses = 0\n",
        "          game_over = False\n",
        "\n",
        "          while not game_over:\n",
        "              state = self.get_state(\"\".join(guessed_word), used_letters, incorrect_guesses)\n",
        "              #q_values = self.model(state).detach().cpu().numpy()  # Get Q-values for actions\n",
        "              q_values = nn.functional.softmax(self.model(state), dim=-1).detach().cpu().numpy()\n",
        "              # Exclude already used letters\n",
        "              for used_letter in used_letters:\n",
        "                  q_values[0][ord(used_letter) - 97] = -np.inf\n",
        "\n",
        "              action = chr(np.argmax(q_values) + 97)\n",
        "              used_letters.append(action)\n",
        "\n",
        "              if action in word:\n",
        "                  for i, letter in enumerate(word):\n",
        "                      if letter == action:\n",
        "                          guessed_word[i] = action\n",
        "              else:\n",
        "                incorrect_guesses += 1  # Increment the counter if the guess was incorrect\n",
        "\n",
        "\n",
        "              game_over = \"_\" not in guessed_word or len(used_letters) > 10\n",
        "\n",
        "          # Check if the game was a success\n",
        "          if \"_\" not in guessed_word:\n",
        "              total_success += 1\n",
        "\n",
        "      print(f\"Success rate: {total_success/games:.2%}\")\n",
        "      return total_success"
      ],
      "metadata": {
        "id": "IAAHFxVSXKHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(QNetwork, self).__init__()\n",
        "\n",
        "        # First hidden layer\n",
        "        self.fc1 = nn.Linear(input_dim, 64)  # Increased neurons to 64\n",
        "        # Second hidden layer\n",
        "        self.fc2 = nn.Linear(64, 64)  # Introduced an additional layer with 64 neurons\n",
        "        # Third hidden layer\n",
        "        self.fc3 = nn.Linear(64, 48)  # Introduced another layer with 48 neurons\n",
        "        # Output layer\n",
        "        self.fc4 = nn.Linear(48, output_dim)\n",
        "\n",
        "        # Initialize weights with Kaiming Initialization for LeakyReLU\n",
        "        '''\n",
        "        init.kaiming_normal_(self.fc1.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc2.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc3.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc4.weight, nonlinearity='leaky_relu')\n",
        "        '''\n",
        "        # Define LeakyReLU activation function\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        return nn.functional.softmax(self.fc4(x), dim=-1)  # Softmax added here\n",
        "\n",
        "\n",
        "class HangmanDQL:\n",
        "    def __init__(self, word_list):\n",
        "        self.word_list = word_list\n",
        "        self.epsilon = 0.2\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.95\n",
        "        self.learning_rate = 3*0.0001 #0.00055 #0.001\n",
        "        self.model = QNetwork(26 + 29+5, 26).to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.MAX_CHANCES = 10\n",
        "\n",
        "    def get_state(self, word, used_letters,incorrect_guesses):\n",
        "        state = [1 if char in used_letters else 0 for char in 'abcdefghijklmnopqrstuvwxyz']\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word]\n",
        "\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word] + [0] * (29 - len(word))\n",
        "\n",
        "        # Change word encoding to put -1 if the word is not required or out of scope\n",
        "        word_encoding = [1 if char == \"_\" else 0 for char in word] + [-1] * (29 - len(word))\n",
        "\n",
        "        # a. Length of the word being guessed\n",
        "        word_length = len(word)\n",
        "\n",
        "        # b. Count of correct letters guessed in the current word state\n",
        "        correct_letter_count = sum(word.count(letter) for letter in set(word) if letter != '_')\n",
        "\n",
        "        # c. Total positions correctly guessed\n",
        "        correct_positions = len(word) - word_encoding.count(1)\n",
        "\n",
        "        # d. Total guesses pending\n",
        "        guesses_pending = len(word) - correct_positions\n",
        "\n",
        "        # e. Total chances pending\n",
        "        chances_pending = self.MAX_CHANCES - incorrect_guesses\n",
        "\n",
        "        state_representation = state + word_encoding\n",
        "        #print(\"State representation length:\", len(state_representation))\n",
        "\n",
        "        # sugession\n",
        "        # If you have gussed first word correctly - add a single state to represent what was the first word\n",
        "        # If you have gussed last word correctly - add a single state to represent what was the last word\n",
        "        state_representation = state + word_encoding + [word_length, correct_letter_count, correct_positions, guesses_pending, chances_pending]\n",
        "\n",
        "        return torch.tensor(state_representation, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "          target = reward\n",
        "          if not done:\n",
        "              target = reward + self.gamma * torch.argmax(self.model(next_state)).item()\n",
        "          target_q_values = self.model(state)\n",
        "\n",
        "          # Prepare data for CrossEntropy loss\n",
        "          action_idx = ord(action) - 97\n",
        "          loss = self.criterion(target_q_values, torch.tensor([action_idx]).to(device))\n",
        "\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def train(self, epochs=1000, batch_size=32):\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            #print('Epoch:',_)\n",
        "            print(f'Training Epoch: {_ + 1}/{epochs}')\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses=0\n",
        "            done = False\n",
        "            ## If you have gussed the complete word get a + 10 reward\n",
        "            ## if you have reached the limit of incorrect gusses you get a -10\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "                    incorrect_guesses += 1\n",
        "                # Check if the entire word has been guessed\n",
        "                if \"_\" not in guessed_word:\n",
        "                    reward = 10\n",
        "                    done = True\n",
        "\n",
        "                # Check if the limit of incorrect guesses has been reached\n",
        "                if incorrect_guesses >= self.MAX_CHANCES:\n",
        "                    reward = -10\n",
        "                    done = True\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "\n",
        "                if len(self.memory) > batch_size:\n",
        "                    self.replay(batch_size)\n",
        "            success_rate = self.test(games=500)\n",
        "            #print(f\"Success Rate after Epoch {_ + 1}: {success_rate:.2%}\")\n",
        "\n",
        "    def find_learning_rate(self, init_value=1e-8, final_value=10., beta=0.98):\n",
        "        num = len(self.memory) - 1\n",
        "        mult = (final_value / init_value) ** (1/num)\n",
        "        lr = init_value\n",
        "        self.optimizer.param_groups[0]['lr'] = lr\n",
        "        avg_loss = 0.\n",
        "        best_loss = 0.\n",
        "        batch_num = 0\n",
        "        losses = []\n",
        "        log_lrs = []\n",
        "        for data in self.memory:\n",
        "            batch_num += 1\n",
        "            # Get a mini-batch of training data\n",
        "            state, action, reward, next_state, done = data\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            #target_q_values[0][ord(action) - 97] = target\n",
        "            #target_q_values = self.model(state).clone()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values = target_q_values.clone()\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            # Smooth the average and compute the smoothed loss\n",
        "            avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
        "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "\n",
        "            # Stop if the loss is exploding\n",
        "            if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "                return log_lrs, losses\n",
        "            # Record the best loss\n",
        "            if smoothed_loss < best_loss or batch_num==1:\n",
        "                best_loss = smoothed_loss\n",
        "\n",
        "            # Store the values\n",
        "            losses.append(smoothed_loss)\n",
        "            log_lrs.append(np.log10(lr))\n",
        "\n",
        "            # Update the learning rate\n",
        "            lr *= mult\n",
        "            self.optimizer.param_groups[0]['lr'] = lr\n",
        "\n",
        "            # Perform the optimization step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return log_lrs, losses\n",
        "\n",
        "    def plot_lr_finder(self, log_lrs, losses):\n",
        "        plt.plot(log_lrs, losses)\n",
        "        plt.xlabel(\"Log10 Learning Rate\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Learning Rate Finder\")\n",
        "        plt.show()\n",
        "\n",
        "    def populate_memory(self, games=500):\n",
        "        for _ in range(games):\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses = 0  # Initialize it here\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #print(\"State shape:\", state.shape)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                #print(state.shape)\n",
        "                #print(26 + len(max(self.word_list, key=len)))\n",
        "\n",
        "    def test(self, games=100):\n",
        "      total_success = 0\n",
        "\n",
        "      for _ in range(games):\n",
        "          word = np.random.choice(self.word_list)\n",
        "          guessed_word = [\"_\"] * len(word)\n",
        "          used_letters = []\n",
        "          incorrect_guesses = 0\n",
        "          game_over = False\n",
        "\n",
        "          while not game_over:\n",
        "              state = self.get_state(\"\".join(guessed_word), used_letters, incorrect_guesses)\n",
        "              q_values = self.model(state).detach().cpu().numpy()  # Get Q-values for actions\n",
        "\n",
        "              # Exclude already used letters\n",
        "              for used_letter in used_letters:\n",
        "                  q_values[0][ord(used_letter) - 97] = -np.inf\n",
        "\n",
        "              action = chr(np.argmax(q_values) + 97)\n",
        "              used_letters.append(action)\n",
        "\n",
        "              if action in word:\n",
        "                  for i, letter in enumerate(word):\n",
        "                      if letter == action:\n",
        "                          guessed_word[i] = action\n",
        "              else:\n",
        "                incorrect_guesses += 1  # Increment the counter if the guess was incorrect\n",
        "\n",
        "\n",
        "              game_over = \"_\" not in guessed_word or len(used_letters) > 10\n",
        "\n",
        "          # Check if the game was a success\n",
        "          if \"_\" not in guessed_word:\n",
        "              total_success += 1\n",
        "\n",
        "      print(f\"Success rate: {total_success/games:.2%}\")\n",
        "      return total_success"
      ],
      "metadata": {
        "id": "HsfNg5PKXo4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dictionary_file_location ='/content/drive/MyDrive/Anand_Trexquant/words_250000_train.txt'"
      ],
      "metadata": {
        "id": "zl90-oGwWTAp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def build_dictionary( full_dictionary_location):\n",
        "text_file = open(dictionary_file_location,\"r\")\n",
        "full_dictionary = text_file.read().splitlines()\n",
        "text_file.close()\n",
        "full_dictionary\n",
        "\n",
        "type(full_dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chLaiwCrWZFK",
        "outputId": "d40fe0ea-a2da-48d4-b3bf-400dba5082db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 24)\n",
        "        self.fc2 = nn.Linear(24, 24)\n",
        "        self.fc3 = nn.Linear(24, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "\n",
        "class HangmanDQL:\n",
        "    def __init__(self, word_list):\n",
        "        self.word_list = word_list\n",
        "        self.epsilon = 0.2\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001 #0.00055 #0.001\n",
        "        self.model = QNetwork(26 + 29+5, 26).to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.MAX_CHANCES = 10\n",
        "\n",
        "    def get_state(self, word, used_letters,incorrect_guesses):\n",
        "        state = [1 if char in used_letters else 0 for char in 'abcdefghijklmnopqrstuvwxyz']\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word]\n",
        "        word_encoding = [1 if char == \"_\" else 0 for char in word] + [0] * (29 - len(word))\n",
        "        # a. Length of the word being guessed\n",
        "        word_length = len(word)\n",
        "\n",
        "        # b. Count of correct letters guessed in the current word state\n",
        "        correct_letter_count = sum(word.count(letter) for letter in set(word) if letter != '_')\n",
        "\n",
        "        # c. Total positions correctly guessed\n",
        "        correct_positions = len(word) - word_encoding.count(1)\n",
        "\n",
        "        # d. Total guesses pending\n",
        "        guesses_pending = len(word) - correct_positions\n",
        "\n",
        "        # e. Total chances pending\n",
        "        chances_pending = self.MAX_CHANCES - incorrect_guesses\n",
        "\n",
        "        state_representation = state + word_encoding\n",
        "        #print(\"State representation length:\", len(state_representation))\n",
        "\n",
        "        state_representation = state + word_encoding + [word_length, correct_letter_count, correct_positions, guesses_pending, chances_pending]\n",
        "\n",
        "        return torch.tensor(state_representation, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = np.random.choice(len(self.memory), batch_size)\n",
        "        for i in minibatch:\n",
        "            state, action, reward, next_state, done = self.memory[i]\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def train(self, epochs=1000, batch_size=32):\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            #print('Epoch:',_)\n",
        "            print(f'Training Epoch: {_ + 1}/{epochs}')\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses=0\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "                    incorrect_guesses += 1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "\n",
        "                if len(self.memory) > batch_size:\n",
        "                    self.replay(batch_size)\n",
        "            success_rate = self.test(games=500)\n",
        "            #print(f\"Success Rate after Epoch {_ + 1}: {success_rate:.2%}\")\n",
        "\n",
        "    def find_learning_rate(self, init_value=1e-8, final_value=10., beta=0.98):\n",
        "        num = len(self.memory) - 1\n",
        "        mult = (final_value / init_value) ** (1/num)\n",
        "        lr = init_value\n",
        "        self.optimizer.param_groups[0]['lr'] = lr\n",
        "        avg_loss = 0.\n",
        "        best_loss = 0.\n",
        "        batch_num = 0\n",
        "        losses = []\n",
        "        log_lrs = []\n",
        "        for data in self.memory:\n",
        "            batch_num += 1\n",
        "            # Get a mini-batch of training data\n",
        "            state, action, reward, next_state, done = data\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            # Smooth the average and compute the smoothed loss\n",
        "            avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
        "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "\n",
        "            # Stop if the loss is exploding\n",
        "            if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "                return log_lrs, losses\n",
        "            # Record the best loss\n",
        "            if smoothed_loss < best_loss or batch_num==1:\n",
        "                best_loss = smoothed_loss\n",
        "\n",
        "            # Store the values\n",
        "            losses.append(smoothed_loss)\n",
        "            log_lrs.append(np.log10(lr))\n",
        "\n",
        "            # Update the learning rate\n",
        "            lr *= mult\n",
        "            self.optimizer.param_groups[0]['lr'] = lr\n",
        "\n",
        "            # Perform the optimization step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return log_lrs, losses\n",
        "\n",
        "    def plot_lr_finder(self, log_lrs, losses):\n",
        "        plt.plot(log_lrs, losses)\n",
        "        plt.xlabel(\"Log10 Learning Rate\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Learning Rate Finder\")\n",
        "        plt.show()\n",
        "\n",
        "    def populate_memory(self, games=500):\n",
        "        for _ in range(games):\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses = 0  # Initialize it here\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #print(\"State shape:\", state.shape)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                #print(state.shape)\n",
        "                #print(26 + len(max(self.word_list, key=len)))\n",
        "\n",
        "    def test(self, games=100):\n",
        "      total_success = 0\n",
        "\n",
        "      for _ in range(games):\n",
        "          word = np.random.choice(self.word_list)\n",
        "          guessed_word = [\"_\"] * len(word)\n",
        "          used_letters = []\n",
        "          incorrect_guesses = 0\n",
        "          game_over = False\n",
        "\n",
        "          while not game_over:\n",
        "              state = self.get_state(\"\".join(guessed_word), used_letters, incorrect_guesses)\n",
        "              q_values = self.model(state).detach().cpu().numpy()  # Get Q-values for actions\n",
        "\n",
        "              # Exclude already used letters\n",
        "              for used_letter in used_letters:\n",
        "                  q_values[0][ord(used_letter) - 97] = -np.inf\n",
        "\n",
        "              action = chr(np.argmax(q_values) + 97)\n",
        "              used_letters.append(action)\n",
        "\n",
        "              if action in word:\n",
        "                  for i, letter in enumerate(word):\n",
        "                      if letter == action:\n",
        "                          guessed_word[i] = action\n",
        "              else:\n",
        "                incorrect_guesses += 1  # Increment the counter if the guess was incorrect\n",
        "\n",
        "\n",
        "              game_over = \"_\" not in guessed_word or len(used_letters) > 10\n",
        "\n",
        "          # Check if the game was a success\n",
        "          if \"_\" not in guessed_word:\n",
        "              total_success += 1\n",
        "\n",
        "      print(f\"Success rate: {total_success/games:.2%}\")\n",
        "      return total_success"
      ],
      "metadata": {
        "id": "3EbfzU6CZ0sT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "word_list = [\"ability\", \"absence\", \"academy\", \"account\", \"accuracy\", \"activity\",\n",
        "             \"actually\", \"addition\", \"address\", \"admission\", \"advantage\", \"advice\",\n",
        "             \"adviser\", \"affect\", \"afternoon\", \"situation\", \"associate\", \"attention\",\n",
        "             \"attitude\", \"attribute\", \"audience\", \"authority\", \"available\", \"awareness\",\n",
        "             \"beautiful\", \"certainly\", \"challenge\", \"character\", \"chocolate\", \"collection\",\n",
        "             \"commercial\", \"committee\", \"community\", \"completely\", \"complex\", \"component\",\n",
        "             \"conclusion\", \"condition\", \"conference\", \"confidence\", \"connection\", \"consciousness\",\n",
        "             \"consider\", \"consistent\", \"constant\", \"construction\", \"contain\", \"content\",\n",
        "             \"contribute\", \"contribution\", \"control\", \"conversation\", \"cooperation\", \"corporation\",\n",
        "             \"cultural\", \"currently\", \"dangerous\", \"definition\", \"demonstrate\", \"department\",\n",
        "             \"dependent\", \"designer\", \"determine\", \"developer\", \"development\", \"difference\",\n",
        "             \"difficulty\", \"dimension\", \"direction\", \"director\", \"disappear\", \"discipline\",\n",
        "             \"discovery\", \"discussion\", \"distribute\", \"distribution\", \"diversity\", \"education\",\n",
        "             \"efficiency\", \"electronic\", \"employment\", \"encourage\", \"engineer\", \"entertainment\",\n",
        "             \"environment\", \"especially\", \"establish\", \"evaluation\", \"eventually\", \"everybody\",\n",
        "             \"everything\", \"evidence\", \"exactly\", \"examination\"]\n",
        "\n",
        "agent = HangmanDQL(full_dictionary)\n",
        "agent.populate_memory(games=1000)\n",
        "log_lrs, losses = agent.find_learning_rate()\n",
        "agent.plot_lr_finder(log_lrs, losses)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "U8IX2AbTWc0O",
        "outputId": "1c94ccdb-2f66-4653-f377-cbeee2446862"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = HangmanDQL(full_dictionary)\n",
        "agent.train(epochs=5000)\n",
        "success_count = agent.test(games=100)\n",
        "print(success_count)"
      ],
      "metadata": {
        "id": "uA85Z6M7Wf-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}